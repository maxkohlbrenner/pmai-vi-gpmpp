{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "na = np.newaxisstabilizer\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# import helper functions from utils.py:\n",
    "from utils import build_2d_grid, train_parameters, evaluation, tf_tril_indices, load_lookup_table, table_lookup_op_parallel, get_scp_samples, build_graph, build_eval_graph\n",
    "\n",
    "# colormap\n",
    "cmap = plt.get_cmap('plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning:\n",
    "- get test examples to run, handle ind point limitations\n",
    "- get real world dataset example to run\n",
    "\n",
    "### BUGS:\n",
    "\n",
    "- nans occur for too many ind points (in exp gradient)\n",
    "- m and S values go to infinity if inducing_point_res >= 9\n",
    "\n",
    "(solved?)\n",
    "\n",
    "- implemented logdet for kl div, added stabilizer\n",
    "\n",
    "\n",
    "### TODOS:\n",
    "- clean code into functions\n",
    "- Check T region definition (currently limits of inducing points)\n",
    "- Add inducing point location optimization\n",
    "\n",
    "- calculate and print lower bound for testset\n",
    "- improve 2d sampling function\n",
    "- optimize Lookup Table resolution (Max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2d example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def double_blob_10_10(x):\n",
    "    blob_1 = multivariate_normal.pdf(x, mean = [3, 3], cov=[[1, 0], [0, 1]])\n",
    "    blob_2 = multivariate_normal.pdf(x, mean = [7, 7], cov=[[1, 0], [0, 1]])\n",
    "    return (blob_1 + blob_2) * 10\n",
    "\n",
    "def double_blob(x_in, Tlims):\n",
    "    x = np.zeros(x_in.shape)\n",
    "    x1frac = 10. / (Tlims[0,1] - Tlims[0,0])\n",
    "    x2frac = 10. / (Tlims[1,1] - Tlims[1,0])\n",
    "    x[:,0] = x_in[:,0] * x1frac\n",
    "    x[:,1] = x_in[:,1] * x2frac\n",
    "    return double_blob_10_10(x) * (x1frac * x2frac) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = 100\n",
    "Tlims = np.array([[0., 10.], [0., 10.]])\n",
    "\n",
    "X = build_2d_grid(Tlims, res)\n",
    "vals = double_blob(X, Tlims).reshape(res,res)\n",
    "\n",
    "plt.imshow(vals, interpolation='none', origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper_bound = np.ceil(np.max(vals))\n",
    "samples, _, _, _, _, _ = get_scp_samples(lambda x: double_blob(x, Tlims), Tlims, upper_bound, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of samples: {}'.format(samples.shape[0]))\n",
    "\n",
    "# sampled data:\n",
    "plt.scatter(samples[:,0], samples[:,1], linewidth=0.1, alpha=.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation with learned alphas and increasing number of inducing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## ######## ##\n",
    "# PARAMETERS #\n",
    "## ######## ##\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "check_numerics = True\n",
    "\n",
    "# general options\n",
    "train_hyperparameters    = True\n",
    "optimize_inducing_points = False\n",
    "ind_point_num            = 6\n",
    "\n",
    "# gradient descent optionss\n",
    "max_iterations = 1000\n",
    "learning_rate  = 0.001\n",
    "\n",
    "# initialization:\n",
    "lvech_init_stddev = 0.1 # 0.001\n",
    "m_init_val        = 1.\n",
    "\n",
    "alphas_init = [0.0001,  0.0001]\n",
    "gamma_init  = 1.\n",
    "\n",
    "# tensorboard options:\n",
    "logdir = 'logs/2d_blob'\n",
    "\n",
    "# build_evaluation_grid\n",
    "eval_res = 100\n",
    "eval_grid = build_2d_grid(Tlims, eval_res)\n",
    "\n",
    "i = ind_point_num\n",
    "        \n",
    "m_opt, S_opt, Kzz_inv_opt, alphas_opt, Z_opt,gamma_opt = train_parameters(samples, i, Tlims, \n",
    "                                                                          optimize_inducing_points=optimize_inducing_points, \n",
    "                                                                          train_hyperparameters=train_hyperparameters,\n",
    "                                                                          learning_rate=learning_rate,\n",
    "                                                                          max_iterations=max_iterations,\n",
    "                                                                          log_dir=logdir,\n",
    "                                                                          alphas_init=alphas_init,\n",
    "                                                                          gamma_init=gamma_init,\n",
    "                                                                          lvech_init_stddev=lvech_init_stddev,\n",
    "                                                                          m_init_val=m_init_val,\n",
    "                                                                          check_numerics=check_numerics\n",
    "                                                                         )\n",
    "lam_vals, lam_var = evaluation(m_opt,S_opt,Kzz_inv_opt,alphas_opt,gamma_opt,Z_opt, eval_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plots\n",
    "fig = plt.figure(figsize=(15, 5)) \n",
    "max_value = np.max([np.max(vals), np.max(lam_vals)])\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=max_value)\n",
    "\n",
    "print(\"ind point number: \",i)\n",
    "print(\"alphas: \",alphas_opt)\n",
    "print(\"gamma: \",gamma_opt)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(Tlims[0,0], Tlims[0,1], eval_res), np.linspace(Tlims[1,0], Tlims[1,1], eval_res))\n",
    "\n",
    "ax0 = plt.subplot(1,2,1)\n",
    "im = ax0.pcolormesh(xx, yy, lam_vals.reshape(eval_res,eval_res), cmap=cmap, norm=norm)\n",
    "fig.colorbar(im, ax=ax0)\n",
    "ax0.set_title('prediciton with samples')\n",
    "# ax0.scatter(samples[:,0], samples[:,1])\n",
    "plt.xlim(Tlims[0,0], Tlims[0,1])\n",
    "plt.ylim(Tlims[1,0], Tlims[1,1])\n",
    "\n",
    "ax1 = plt.subplot(1,2, 2)\n",
    "im1 = ax1.pcolormesh(xx, yy, vals, cmap=cmap,norm=norm)\n",
    "fig.colorbar(im1, ax=ax1)\n",
    "ax1.set_title('groundtruth with inducing points')\n",
    "ax1.scatter(Z_opt[:, 0], Z_opt[:,1])\n",
    "plt.xlim(Tlims[0,0], Tlims[0,1])\n",
    "plt.ylim(Tlims[1,0], Tlims[1,1])\n",
    "#plt.savefig('results/' + run_prefix + '_result.png', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
