{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "na = np.newaxis\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GPflow/GPflow/issues/439\n",
    "def tf_tril_indices(N, k=0):\n",
    "    M1 = tf.tile(tf.expand_dims(tf.range(N), axis=0), [N,1])\n",
    "    M2 = tf.tile(tf.expand_dims(tf.range(N), axis=1), [1,N])\n",
    "    mask = (M1-M2) >= -k\n",
    "    ix1 = tf.boolean_mask(M2, tf.transpose(mask))\n",
    "    ix2 = tf.boolean_mask(M1, tf.transpose(mask))\n",
    "    return ix1, ix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ard_kernel(X1, X2, gamma=1., alphas=None):\n",
    "    # X1:  (n1 x d)\n",
    "    # X2:  (n2 x d)\n",
    "    # out: (n1 x n2\n",
    "    with tf.name_scope('ard_kernel'):\n",
    "        if alphas is None:\n",
    "            alphas = tf.ones([tf.shape(X1)[1]])\n",
    "        return gamma * tf.reduce_prod(tf.exp(- (tf.expand_dims(X1, 1) - tf.expand_dims(X2, 0))**2 / (2 * tf.expand_dims(tf.expand_dims(alphas, 0), 0))), axis=2) \n",
    "\n",
    "\n",
    "def mu_tilde_square(X_data, Z, m, Kzz_inv):\n",
    "    k_zx = ard_kernel(X_data, Z, alphas=a_const)\n",
    "    k_xz = tf.transpose(k_zx)\n",
    "    k_xx = ard_kernel(X_data, Z, alphas=a_const)\n",
    "    mu_sqr = tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(tf.expand_dims(m,1)),Kzz_inv)\n",
    "                                                     ,k_zx),k_xz),Kzz_inv),tf.expand_dims(m,1))\n",
    "    sig_sqr = k_xx - tf.trace(tf.matmul(tf.matmul(Kzz_inv,k_zx),k_xz)) + tf.trace(\n",
    "        tf.matmul(tf.matmul(tf.matmul(tf.matmul(Kzz_inv,S),Kzz_inv),k_zx),k_xz))\n",
    "    return mu_sqr, sig_sqr\n",
    "\n",
    "def kl_term(m, S, K_zz, K_zz_inv, u_ovln):\n",
    "    # mean_diff = (u_ovln * tf.ones([tf.shape(Z_ph)[0]]) - m)\n",
    "    mean_diff = tf.expand_dims(u_ovln * tf.ones([tf.shape(Z_ph)[0]]) - m, 1)\n",
    "    first  = tf.trace(tf.matmul(K_zz_inv, S))\n",
    "    second = tf.log(tf.matrix_determinant(K_zz) / tf.matrix_determinant(S))\n",
    "    third  = tf.to_float(tf.shape(m)[0])\n",
    "    # fourth = tf.reduce_sum(tf.multiply(tf.reduce_sum(tf.multiply(mean_diff, tf.transpose(K_zz_inv)), axis=1) , mean_diff))\n",
    "    \n",
    "    fourth = tf.squeeze(tf.matmul(tf.matmul(tf.transpose(mean_diff), K_zz_inv), mean_diff))\n",
    "    \n",
    "    return 0.5 * (first  + second - third + fourth)\n",
    "\n",
    "def psi_term(Z1, Z2,a,g,Tmin,Tmax):\n",
    "    z_ovln = (tf.expand_dims(Z1,1)+tf.expand_dims(Z2,0))/2\n",
    "    a_r = tf.expand_dims(tf.expand_dims(a,0),1)\n",
    "    \n",
    "    pi = tf.constant(math.pi)\n",
    "    \n",
    "    return g**2 * tf.reduce_prod(-(tf.sqrt(pi * a_r)/2\n",
    "                   ) * tf.exp(-tf.pow(tf.expand_dims(Z1,1) - tf.expand_dims(Z2,0),2) / (4 * a_r)\n",
    "                             ) * tf.erf((z_ovln-tf.expand_dims(tf.expand_dims(Tmax,0),1))/tf.sqrt(a_r)\n",
    "                                     ) - tf.erf((z_ovln-tf.expand_dims(tf.expand_dims(Tmin,0),1))/tf.sqrt(a_r)),2)\n",
    "\n",
    "def T_Integral(m, S, Kzz_inv,psi, g,Tmin, Tmax):\n",
    "    #e_qf = tf.matmul(m,tf.matmul(Kzz_inv,tf.matmul(psi,tf.matmul(Kzz_inv,m))))\n",
    "    e_qf = tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(tf.expand_dims(m,1)),Kzz_inv),psi),Kzz_inv),tf.expand_dims(m,1))\n",
    "    T = tf.reduce_prod(Tmax-Tmin)\n",
    "    var_qf = g * T - tf.trace(tf.matmul(Kzz_inv,psi)) + tf.trace(tf.matmul(tf.matmul(tf.matmul(Kzz_inv,S),Kzz_inv),psi))\n",
    "    return e_qf + var_qf\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "Z_ph = tf.placeholder(tf.float32, [None, None], name='inducing_point_locations')\n",
    "u_ph = tf.placeholder(tf.float32, [],           name='inducing_point_mean')\n",
    "n_ph = tf.placeholder(tf.int32,   [],           name='number_samples')\n",
    "\n",
    "X_ph =tf.placeholder(tf.float32, [None, None])\n",
    "\n",
    "a_const = tf.ones([1]) # dimension = tf.shape(Z_ph)[1]\n",
    "g_const = tf.ones([1]) # later we have to define gamma as variable\n",
    "\n",
    "#Tlims\n",
    "Tmins = tf.reduce_min(Z_ph, axis=0)\n",
    "Tmaxs = tf.reduce_max(Z_ph, axis=0)\n",
    "\n",
    "num_inducing_points = 11 # tf.shape(Z_ph)[0] TODO: use shape of Z_ph instead? Right now, the number is defined twice (once here, one above in the definition of Z)\n",
    "\n",
    "# mean\n",
    "m_init = tf.ones([num_inducing_points])\n",
    "m = tf.Variable(m_init)\n",
    "\n",
    "# vectorized version of covariance matrix S (ensure valid covariance matrix)\n",
    "vech_size   = (num_inducing_points * (num_inducing_points+1)) / 2 \n",
    "vech_indices= tf.transpose(tf_tril_indices(num_inducing_points))\n",
    "L_vech_init = tf.ones([vech_size])\n",
    "L_vech = tf.Variable(L_vech_init)\n",
    "L_shape = tf.constant([num_inducing_points, num_inducing_points])\n",
    "L_st = tf.SparseTensor(tf.to_int64(vech_indices), L_vech, tf.to_int64(L_shape))\n",
    "L = tf.sparse_add(tf.zeros(L_shape), L_st)\n",
    "S = tf.matmul(L, tf.transpose(L))\n",
    "\n",
    "# kernel calls\n",
    "K_zz  = ard_kernel(Z_ph, Z_ph, alphas=a_const)\n",
    "K_zz_inv = tf.matrix_inverse(K_zz)\n",
    "\n",
    "with tf.name_scope('intergration-over-region-T'):\n",
    "    psi_matrix = psi_term(Z_ph,Z_ph,a_const,g_const,Tmins,Tmaxs)\n",
    "    integral_over_T = T_Integral(m,S,K_zz_inv,psi_matrix,g_const,Tmins,Tmaxs)\n",
    "    \n",
    "with tf.name_scope('expectation_at_datapoints'):\n",
    "    mu_t_sqr, sig_t_sqr = mu_tilde_square(X_ph,Z_ph,m,K_zz_inv)\n",
    "\n",
    "with tf.name_scope('KL-divergence'):\n",
    "    kl_term_op = kl_term(m, S, K_zz, K_zz_inv, u_ph)\n",
    "    tf.summary.scalar('kl_div', kl_term_op)\n",
    "\n",
    "with tf.name_scope('calculate_bound'):\n",
    "    lower_bound = -integral_over_T - kl_term_op\n",
    "    \n",
    "with tf.name_scope('optimization'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.001).minimize(-lower_bound)\n",
    "\n",
    "with tf.name_scope('prior_sampling'):\n",
    "    cov  = K_zz\n",
    "    mean = u_ph * tf.ones([num_inducing_points])\n",
    "    ind_point_dist = tf.contrib.distributions.MultivariateNormalFullCovariance(mean, cov)\n",
    "    samples = ind_point_dist.sample(n_ph)\n",
    "    \n",
    "m_grad = tf.gradients(kl_term_op, [m])[0]  \n",
    "L_vech_grad = tf.gradients(kl_term_op, [L_vech])[0]\n",
    "\n",
    "    \n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "28.3563\n",
      "[[ 517.80090332]]\n",
      "[[-546.15716553]]\n",
      "..........\n",
      "7.90047\n",
      "[[ 242.81924438]]\n",
      "[[-250.7197113]]\n",
      "..........\n",
      "4.85578\n",
      "[[ 207.74171448]]\n",
      "[[-212.59750366]]\n",
      "..........\n",
      "3.35076\n",
      "[[ 199.58575439]]\n",
      "[[-202.93652344]]\n",
      "..........\n",
      "2.54282\n",
      "[[ 195.17651367]]\n",
      "[[-197.71932983]]\n",
      "..........\n",
      "2.37794\n",
      "[[ 190.37214661]]\n",
      "[[-192.75009155]]\n",
      "..........\n",
      "3.01659\n",
      "[[ 183.2542572]]\n",
      "[[-186.27084351]]\n",
      "..........\n",
      "4.86926\n",
      "[[ 171.57136536]]\n",
      "[[-176.44062805]]\n",
      "..........\n",
      "8.74123\n",
      "[[ 151.62142944]]\n",
      "[[-160.36265564]]\n",
      "..........\n",
      "16.1212\n",
      "[[ 116.83110809]]\n",
      "[[-132.95230103]]\n",
      "..........\n",
      "29.7232\n",
      "[[ 55.28117371]]\n",
      "[[-85.0043869]]\n",
      "..........\n",
      "54.4928\n",
      "[[-54.84334946]]\n",
      "[[ 0.35055161]]\n",
      "..........\n",
      "99.4755\n",
      "[[-253.7191925]]\n",
      "[[ 154.24368286]]\n",
      "..........\n",
      "181.297\n",
      "[[-615.7164917]]\n",
      "[[ 434.41964722]]\n",
      "..........\n",
      "330.665\n",
      "[[-1279.10717773]]\n",
      "[[ 948.44250488]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAG25JREFUeJzt3X2QVfWd5/H3R56DSQOCdgs4gIMa\nJyEr1eNDZZ2NdgZ8CGl3xrXIplbiuEVtNpmgScxIrBg2U1NJxlQQK1kzVHRWt5wY1rACwVlUQnat\nUomNJvgASEM00HSHNkgnQUAavvvH+TXebhvp2/d230ufz6uqq8/5nt8998uh+3z6nnPuuYoIzMws\nv06rdANmZlZZDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWc8Mr3UBf\nTJw4MaZNm1bpNszMTimbNm16IyImnWzcKREE06ZNo6mpqdJtmJmdUiS93pdxfT40JOl+SXslvVRQ\nmyDpCUnb0/fxqS5J90hqlrRZ0uyCxyxI47dLWlDMP8rMzMqvmHME/wO4qkftdmB9RMwE1qd5gKuB\nmelrIXAvZMEBfB24BLgY+HpXeJiZWWX0OQgi4v8B+3qUG4EH0vQDwHUF9Qcj8ywwTlIdMBd4IiL2\nRcSbwBO8O1zMzGwQlXrV0FkR0Zqm24Cz0vRkYFfBuN2pdqL6u0haKKlJUlN7e3uJbZqZ2YmU7fLR\nyD7YoGwfbhARyyOiPiLqJ0066UlvMzPrp1KD4LfpkA/p+95UbwGmFoybkmonqpuZWYWUGgSrga4r\nfxYAqwrqN6arhy4FOtIhpHXAHEnj00niOalmZmYV0uf3EUj6EfAxYKKk3WRX/3wLWCHpZuB14IY0\n/DHgGqAZeAu4CSAi9kn6e+C5NO4bEdHzBLSZWS69urGNZ1bt4I/7DnP6hFFc1ngu511SO+DPq1Ph\nM4vr6+vDbygzs6Hs1Y1tbHhoK51vHzteGz7yNK749AX9DgNJmyKi/mTjfK8hM7Mq8MyqHd1CAKDz\n7WM8s2rHgD+3g8DMrAr8cd/hourl5CAwM6sCp08YVVS9nBwEZmZV4LLGcxk+svsuefjI07is8dwB\nf+5T4u6jZmZDXdcJ4UpcNeQgMDOrEuddUjsoO/6efGjIzCznHARmZjnnIDAzyzkHgZlZzjkIzMxy\nzkFgZpZzDgIzs5xzEJiZ5ZyDwMws5xwEZmY55yAwM8u5sgSBpFslvSzpJUk/kjRa0nRJGyU1S/qx\npJFp7Kg035yWTytHD2Zm1j8lB4GkycAXgPqI+BAwDJgPfBtYGhF/CrwJ3JwecjPwZqovTePMzKxC\nynVoaDgwRtJw4H1AK3Al8Eha/gBwXZpuTPOk5Q2SVKY+zMysSCUHQUS0AN8BfkMWAB3AJmB/RHSm\nYbuByWl6MrArPbYzjT+j1D7MzKx/ynFoaDzZX/nTgbOBscBVZVjvQklNkpra29tLXZ2ZmZ1AOQ4N\nfRz4dUS0R8QRYCXwUWBcOlQEMAVoSdMtwFSAtLwG+F3PlUbE8oioj4j6SZMmlaFNMzPrTTmC4DfA\npZLel471NwCvABuA69OYBcCqNL06zZOW/ywiogx9mJlZP5TjHMFGspO+zwMvpnUuB/4O+KKkZrJz\nAPelh9wHnJHqXwRuL7UHMzPrP50Kf4zX19dHU1NTpdswMzulSNoUEfUnG+d3FpuZ5ZyDwMws5xwE\nZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnO\nOQjMzHLOQWBmlnMOAjOznHMQmJnlXFmCQNI4SY9I2ippi6TLJE2Q9ISk7en7+DRWku6R1Cxps6TZ\n5ejBzMz6p1yvCJYB/yciLgA+Amwh+yzi9RExE1jPO59NfDUwM30tBO4tUw9mZtYPJQeBpBrgL0gf\nTh8Rb0fEfqAReCANewC4Lk03Ag9G5llgnKS6UvswM7P+KccrgulAO/DPkl6Q9ENJY4GzIqI1jWkD\nzkrTk4FdBY/fnWpmZlYB5QiC4cBs4N6IuAg4wDuHgQCIiACimJVKWiipSVJTe3t7Gdo0M7PelCMI\ndgO7I2Jjmn+ELBh+23XIJ33fm5a3AFMLHj8l1bqJiOURUR8R9ZMmTSpDm2Zm1puSgyAi2oBdks5P\npQbgFWA1sCDVFgCr0vRq4MZ09dClQEfBISQzMxtkw8u0nr8FHpI0EtgJ3EQWMisk3Qy8DtyQxj4G\nXAM0A2+lsWZmViFlCYKI+CVQ38uihl7GBvC5cjyvmZmVzu8sNjPLOQeBmVnOOQjMzHLOQWBmlnMO\nAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5ZyDwMys\nHzrWrGH7lQ1s+eCFbL+ygY41ayrdUr+V64NpzMxyo2PNGlq/didx6BAAnXv20Pq1OwGomTevkq31\ni18RmJkVae/Su4+HQJc4dIi9S++uUEelKVsQSBom6QVJP03z0yVtlNQs6cfpYyyRNCrNN6fl08rV\ng5nZYOhs7f1j1k9Ur3blfEWwCNhSMP9tYGlE/CnwJnBzqt8MvJnqS9M4M7NTxvC6uqLq1a4sQSBp\nCnAt8MM0L+BK4JE05AHgujTdmOZJyxvSeDOzU8KZt96CRo/uVtPo0Zx56y0V6qg05TpZfDfwFeD9\naf4MYH9EdKb53cDkND0Z2AUQEZ2SOtL4N8rUi5nZgOo6Ibx36d10trYyvK6OM2+95ZQ8UQxlCAJJ\nnwD2RsQmSR8rvaXj610ILAQ455xzyrVaM7OyqJk375Td8fdUjkNDHwU+Kek14GGyQ0LLgHGSuoJm\nCtCSpluAqQBpeQ3wu54rjYjlEVEfEfWTJk0qQ5tmZtabkoMgIhZHxJSImAbMB34WEZ8GNgDXp2EL\ngFVpenWaJy3/WUREqX2YmVn/DOT7CP4O+KKkZrJzAPel+n3AGan+ReD2AezBzMxOoqzvLI6InwM/\nT9M7gYt7GXMI+A/lfF4zM+s/v7PYzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xz\nEJiZ5ZyDwMws5xwEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeWcg8DMLOccBGZm\nOVdyEEiaKmmDpFckvSxpUapPkPSEpO3p+/hUl6R7JDVL2ixpdqk9mJlZ/5XjFUEn8KWIuBC4FPic\npAvJPpR+fUTMBNbzzofUXw3MTF8LgXvL0IOZmfVTyUEQEa0R8Xya/gOwBZgMNAIPpGEPANel6Ubg\nwcg8C4yTVFdqH2Zm1j9lPUcgaRpwEbAROCsiWtOiNuCsND0Z2FXwsN2p1nNdCyU1SWpqb28vZ5tm\nZlagbEEg6XTgJ8AtEfH7wmUREUAUs76IWB4R9RFRP2nSpHK1aWZmPZQlCCSNIAuBhyJiZSr/tuuQ\nT/q+N9VbgKkFD5+SamZmVgHluGpIwH3Aloj4bsGi1cCCNL0AWFVQvzFdPXQp0FFwCMnMrKzW7lzL\nnEfmMOuBWcx5ZA5rd66tdEtVZ3gZ1vFR4D8BL0r6Zap9FfgWsELSzcDrwA1p2WPANUAz8BZwUxl6\nMDN7l7U717Lk6SUcOnoIgNYDrSx5egkA1864toKdVRdlh++rW319fTQ1NVW6DTM7xcx5ZA6tB959\nwKFubB2PX/94BToaXJI2RUT9ycb5ncVmNmS1HWgrqp5XDgIzG7Jqx9YWVc8rB4GZDVmLZi9i9LDR\n3Wqjh41m0exFFeqoOpXjZLGZWVXqOiG87PlltB1oo3ZsLYtmL/KJ4h4cBGY2pF0741rv+E/Ch4bM\nzHLOQWBmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xz\nEJiZ5VzFgkDSVZK2SWqWdHul+jCzKrJ5BSz9ECwZl33fvKLSHeVCRe4+KmkY8H3gL4HdwHOSVkfE\nK5Xox8yqwOYVsOYLcORgNt+xK5sHmHXDiR9nJavUK4KLgeaI2BkRbwMPA40V6sXMqsH6b7wTAl2O\nHMzqNqAqFQSTgV0F87tT7ThJCyU1SWpqb28f1ObMrAI6dhdXt7Kp2pPFEbE8Iuojon7SpEmVbsfM\nBlrNlOLqVjaVCoIWYGrB/JRUM7O8argTRozpXhsxJqvbgKpUEDwHzJQ0XdJIYD6wukK9mFk1mHUD\nzLsHaqYCyr7Pu8cnigdBRa4aiohOSZ8H1gHDgPsj4uVK9GJmVWTWDd7xV0DFPrw+Ih4DHqvU85uZ\nWaZqTxabmdngcBCYmeWcg8DMLOcqdo7AzE5dj77Qwl3rtrFn/0HOHjeG2+aez3UXTT75A60qOQjM\nrCiPvtDC4pUvcvDIUQBa9h9k8coXARwGpygfGjKzoty1btvxEOhy8MhR7lq3rUIdWakcBGZWlD37\nDxZVt+rnIDCzopw9bkxRdat+DgIzK8ptc89nzIhh3WpjRgzjtrnnV6gjK5VPFpsNcT9p28c3d7bS\ncvgIk0eNYPGMOv66dkK/19d1QthXDQ0dDgKzIewnbfv48rZdHDwWAOw+fIQvb8s+CqTUMPCOf+jw\noSGzIeybO1uPh0CXg8eCb+5srVBHVo38isCsSrS2rWLnju9w6HAro0fVMePcL1NXW9onuLYcPlJU\n3fLJrwjMqkBr2yq2br2DQ4f3AMGhw3vYuvUOWttWlbTeyaNGFFW3fHIQmFWBnTu+w7Fj3a/DP3bs\nIDt3fKek9S6eUceY09StNuY0sXhGXUnrtaHFh4bMirR582bWr19PR0cHNTU1NDQ0MGvWrJLWeehw\n78fsT1Tvq64TwuW8asiGHgeBDWkHXtjL79e9xtH9hxk2bhQfmDuNsRed2e/1bd68mTVr1nDkSHaM\nvaOjgzVr1gCUFAajR9Wlw0Lvrpfqr2sneMdv76mkIJB0FzAPeBvYAdwUEfvTssXAzcBR4AsRsS7V\nrwKWkX1E5Q8j4lul9GCD79WNbTyzagd/3HeY0yeM4rLGcznvktqS1rnlqQ089fCD/OF3b/D+MyZy\n+fwb+eDlV5S0zgMv7GX/yu3EkWMAHN1/mP0rtwP0OwzWr19/PAS6HDlyhPXr15cUBDPO/TJbt97R\n7fDQaaeNYca5X+73Os36qtRzBE8AH4qIWcCrwGIASReSfSD9nwFXAf9d0jBJw4DvA1cDFwKfSmNt\nAHSsWcP2KxvY8sEL2X5lAx3pL9dSvLqxjQ0PbeWP+w4D8Md9h9nw0FZe3djW73VueWoDjy//Hn94\nox0i+MMb7Ty+/HtseWpDSb3+ft1rx0OgSxw5xu/XvdbvdXZ0dBRV76u62kYuuOAfGD3qbECMHnU2\nF1zwDyVfNWTWFyW9IoiIxwtmnwWuT9ONwMMRcRj4taRm4OK0rDkidgJIejiNfaWUPoaCtTvXsuz5\nZbQdaKN2bC2LZi/i2hnX9nt9HWvW0Pq1O4lDhwDo3LOH1q/dCUDNvHn9Xu8zq3bQ+Xb3nWvn28d4\nZtWOfr8qeOrhB+l8+3CPdR7mqYcfLOlVwdH9h4uq90VNTU2vO/2ampp+r7NLXW2jd/xWEeW8auhv\ngH9N05OBXQXLdqfaieq5tnbnWpY8vYTWA60EQeuBVpY8vYS1O9f2e517l959PAS6xKFD7F16d0m9\ndr0S6Gu9L/7wuzeKqvfVsHGjiqr3RUNDAyNGdL/0csSIETQ0NPR7nWaVdtIgkPSkpJd6+WosGHMH\n0Ak8VK7GJC2U1CSpqb29vVyrrUrLnl/GoaPdd9qHjh5i2fPL+r3OztberzY5Ub2vTp/Q+070RPW+\neP8ZE4uq99UH5k5DI7r/iGvEaXxg7rR+r3PWrFnMmzfv+CuAmpoa5s2bV/JVQ2aVdNJDQxHx8fda\nLukzwCeAhojoei97CzC1YNiUVOM96j2fdzmwHKC+vj56GzNUtB3o/fj6iep9Mbyujs49774KZXhd\naVehXNZ4Lhse2trt8NDwkadxWeO5/V7n5fNv5PHl3+t2eGj4yFFcPv/GknrtOiFczquGIAsD7/ht\nKCn1qqGrgK8A/y4i3ipYtBr4F0nfBc4GZgK/AATMlDSdLADmA/+xlB6GgtqxtbQeePdf6rVj+38l\nzpm33tLtHAGARo/mzFtv6fc6gePnAcp51VDXeYByXzUEWRiUuuM3G+pKfR/B94BRwBOSAJ6NiP8S\nES9LWkF2ErgT+FxEHAWQ9HlgHdnlo/dHxMsl9jC4Nq+A9d+Ajt1QMwUa7oRZN5S0ykWzF7Hk6SXd\nDg+NHjaaRbMX9XudXSeE9y69m87WVobX1XHmrbeUdKK4y3mX1JZ8uWhPH7z8irLs+M2seHrnaE71\nqq+vj6ampkq3kYXAmi/AkYJbAYwYA/PuKTkMyn3VkJmZpE0RUX/ScQ6CIiz9EHTsene9Zirc+tLg\n92Nm9h76GgS+6VwxOnYXVzczOwU4CIpRM6W4upnZKcBBUIyGO7NzAoVGjMnqZmanKAdBMWbdkJ0Y\nrpkKKPtehhPFZmaV5NtQF2vWDd7xm9mQ4lcEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7Oc\ncxCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOlSUIJH1JUkiamOYl6R5JzZI2S5pdMHaBpO3pa0E5\nnt/MzPqv5JvOSZoKzAF+U1C+muwD62cClwD3ApdImgB8HagHAtgkaXVEvFlqH2Zm1j/leEWwFPgK\n2Y69SyPwYGSeBcZJqgPmAk9ExL60838CuKoMPZiZWT+VFASSGoGWiPhVj0WTgcIP992daieqm5lZ\nhZz00JCkJ4HaXhbdAXyV7LBQ2UlaCCwEOOeccwbiKczMjD4EQUR8vLe6pA8D04FfSQKYAjwv6WKg\nBZhaMHxKqrUAH+tR//kJnnc5sBygvr4+ehtjZmal6/ehoYh4MSLOjIhpETGN7DDP7IhoA1YDN6ar\nhy4FOiKiFVgHzJE0XtJ4slcT60r/Z5iZWX8N1EdVPgZcAzQDbwE3AUTEPkl/DzyXxn0jIvYNUA9m\nZtYHZQuC9KqgazqAz51g3P3A/eV6XjMzK43fWWxmlnMOAjOznHMQmJnlnIPAzCznHARmZjnnIDAz\nyzkHgZlZzjkIzMxyzkFgZpZzDgIzs5xzEJiZ5dxA3XSuKjz6Qgt3rdvGnv0HOXvcGG6bez7XXeTP\nwTEzKzRkg+DRF1pYvPJFDh45CkDL/oMsXvkigMPAzKzAkD00dNe6bcdDoMvBI0e5a922CnVkZlad\nhmwQ7Nl/sKi6mVleDdkgOHvcmKLqZmZ5NWSD4La55zNmxLButTEjhnHb3PMr1JGZWXUqOQgk/a2k\nrZJelvSPBfXFkpolbZM0t6B+Vao1S7q91Oc/kesumsw3/+rDTB43BgGTx43hm3/1YZ8oNjProaSr\nhiRdATQCH4mIw5LOTPULgfnAnwFnA09KOi897PvAX5J92P1zklZHxCul9HEi11002Tt+M7OTKPXy\n0c8C34qIwwARsTfVG4GHU/3XkpqBi9Oy5ojYCSDp4TR2QILAzMxOrtRDQ+cBl0vaKOn/SvrzVJ8M\n7CoYtzvVTlQ3M7MKOekrAklPArW9LLojPX4CcCnw58AKSTPK0ZikhcBCgHPOOaccqzQzs16cNAgi\n4uMnWibps8DKiAjgF5KOAROBFmBqwdApqcZ71Hs+73JgOUB9fX2crE8zM+ufUg8NPQpcAZBOBo8E\n3gBWA/MljZI0HZgJ/AJ4DpgpabqkkWQnlFeX2IOZmZWg1JPF9wP3S3oJeBtYkF4dvCxpBdlJ4E7g\ncxFxFEDS54F1wDDg/oh4+WRPsmnTpjckvV5CnxPJAupU4F4HhnsdGO51YJSr1z/pyyBl++2hTVJT\nRNRXuo++cK8Dw70ODPc6MAa71yH7zmIzM+sbB4GZWc7lJQiWV7qBIrjXgeFeB4Z7HRiD2msuzhGY\nmdmJ5eUVgZmZncCQDoLButNpEf1MlbRB0ivpbq2LUn2CpCckbU/fx6e6JN2T+t8saXYFeh4m6QVJ\nP03z09MtRZol/Ti9H4T0npEfp/pGSdMGuc9xkh5Jd8LdIumyat2ukm5N//8vSfqRpNHVtF0l3S9p\nb7osvKtW9LaUtCCN3y5pwSD2elf6Odgs6X9LGlewrGJ3Re6t14JlX5IUkiam+cHdrhExJL/I3qew\nA5hB9ka3XwEXVrinOmB2mn4/8CpwIfCPwO2pfjvw7TR9DfCvgMhu47GxAj1/EfgX4KdpfgUwP03/\nAPhsmv6vwA/S9Hzgx4Pc5wPAf07TI4Fx1bhdye6t9WtgTMH2/Ew1bVfgL4DZwEsFtaK2JdmtZ3am\n7+PT9PhB6nUOMDxNf7ug1wvTfmAUMD3tH4YN1r6it15TfSrZe6teByZWYrsOyg9/Jb6Ay4B1BfOL\ngcWV7qtHj6vIbsm9DahLtTpgW5r+J+BTBeOPjxuk/qYA64ErgZ+mH8o3Cn7Jjm/j9IN8WZoensZp\nkPqsSTtX9ahX3XblnRsvTkjb6afA3GrbrsC0HjvXorYl8Cngnwrq3cYNZK89lv174KE03W0f0LVt\nB3Nf0VuvwCPAR4DXeCcIBnW7DuVDQ1V9p9P0Ev8iYCNwVkS0pkVtwFlputL/hruBrwDH0vwZwP6I\n6Oyln+O9puUdafxgmA60A/+cDmP9UNJYqnC7RkQL8B3gN0Ar2XbaRHVu10LFbstK/+x2+Ruyv6yh\nCnuV1Ai0RMSveiwa1F6HchBULUmnAz8BbomI3xcuiyzmK34pl6RPAHsjYlOle+mD4WQvue+NiIuA\nA2SHL46rou06nuwzOKaTfWjTWOCqijZVpGrZlicj6Q6yW9w8VOleeiPpfcBXgTsr3ctQDoL3ugNq\nxUgaQRYCD0XEylT+raS6tLwO6PqAn0r+Gz4KfFLSa8DDZIeHlgHjJHXdo6qwn+O9puU1wO8Gqdfd\nwO6I2JjmHyELhmrcrh8Hfh0R7RFxBFhJtq2rcbsWKnZbVvT3T9JngE8An07BxXv0VKlezyX7g+BX\n6fdsCvC8pNrB7nUoB0HV3elUkoD7gC0R8d2CRauBrrP/C8jOHXTVb0xXEFwKdBS8PB9QEbE4IqZE\nxDSybfeziPg0sAG4/gS9dv0brk/jB+WvxohoA3ZJOj+VGshueFh125XskNClkt6Xfh66eq267dpD\nsdtyHTBH0vj0KmhOqg04SVeRHdL8ZES81ePfUDV3RY6IFyPizIiYln7PdpNdTNLGYG/XgTghUi1f\nZGfeXyW7IuCOKujn35K9pN4M/DJ9XUN2zHc9sB14EpiQxovsM553AC8C9RXq+2O8c9XQDLJfnmbg\nfwGjUn10mm9Oy2cMco//BmhK2/ZRsisqqnK7Av8N2Aq8BPxPsqtYqma7Aj8iO39xhGzndHN/tiXZ\n8fnm9HXTIPbaTHYcvet37AcF4+9IvW4Dri6oD/i+ordeeyx/jXdOFg/qdvU7i83Mcm4oHxoyM7M+\ncBCYmeWcg8DMLOccBGZmOecgMDPLOQeBmVnOOQjMzHLOQWBmlnP/H4wMjyjIMS1AAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febf0745ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_iterations = 1500\n",
    "\n",
    "# inducing point location\n",
    "Zx = np.linspace(0, 20, 11)[:,na]\n",
    "Zy = np.linspace(0, 10, 11)[:,na]\n",
    "\n",
    "Z = np.concatenate((Zx,Zy),axis=1)\n",
    "\n",
    "X = np.random.rand(10,2)\n",
    "\n",
    "wr_means = []\n",
    "wr_covar = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        _, summary, kl, integral,bound, m_val, S_val = sess.run([train_step, merged,  kl_term_op, integral_over_T ,lower_bound, m, S], \n",
    "                                                     feed_dict={Z_ph:Z, u_ph:0.,X_ph:X})\n",
    "        writer.add_summary(summary, i)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('..........')\n",
    "            print(kl)\n",
    "            print(integral)\n",
    "            print(bound)\n",
    "            #print(np.max(np.absolute(S_val)))\n",
    "            #print(np.all(np.linalg.eigvals(S_val) > 0))\n",
    "            \n",
    "            plt.scatter(i, bound)\n",
    "            \n",
    "        if np.isclose(kl, 0):\n",
    "            print('KL is zero after {} iterations... break'.format(i))\n",
    "            break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ard_kernel_np(X1, X2, gamma = 1., alphas = None):\n",
    "    \n",
    "    if alphas == None:\n",
    "        alphas = np.ones(X1.shape[1])\n",
    "    \n",
    "    return gamma * np.prod(np.exp( - (X1[:,None,:] - X2[None,:,:])**2 / (2 * alphas[None,None,:])), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "r_mean = np.zeros(num_inducing_points)\n",
    "r_cov = ard_kernel_np(Z, Z)\n",
    "\n",
    "print(np.allclose(r_mean, m_val))\n",
    "print(np.allclose(r_cov, S_val))\n",
    "\n",
    "print(np.sum(r_cov - S_val)**2)\n",
    "\n",
    "# values not allclose but almost the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "num_samples = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    sample_res, mean_res, cov_res = sess.run([samples, mean, cov], feed_dict={Z_ph:Z, u_ph:0., n_ph:num_samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    plt.plot(Z, sample_res[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inputs:\n",
    "Domain $X = \\mathbb{R}^R$ ($R$-Dimensional)\n",
    "$T \\subset X$\n",
    "\n",
    "\n",
    "### Fixed:\n",
    "\n",
    "#### General:\n",
    "- R\n",
    "- Tlims: (Rx2)\n",
    "- Data D: (NxR) (all points in T)\n",
    "\n",
    "#### Inducing points:\n",
    "    -> fix nbr M \n",
    "    -> Z: (MxR) location\n",
    "    -> u: (M) (each sample of function values at the inducing points is M dimensional) \n",
    "\n",
    "#### Hyperparameters ($\\Theta$)\n",
    "    -> fixed at first, might become be optimized later as well\n",
    "$\\Theta = (\\gamma, \\alpha_1,...,  \\alpha_R, \\overline{u})$\n",
    "\n",
    "\n",
    "### Parameters:\n",
    "variational dist at inducing points u: q(u) = N (u;m,S)\n",
    "\n",
    "m: (M)\n",
    "\n",
    "S: (MxM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo stuff, no working code!!!\n",
    "\n",
    "# constants:\n",
    "# - R, T, M\n",
    "# - D (NxR)\n",
    "# - Z (MxR)\n",
    "# - Theta values (gamma, alphas, ustrich)\n",
    "\n",
    "# placeholders:\n",
    "# - m (M)\n",
    "# - S (MxM)\n",
    "\n",
    "\n",
    "# kernel stuff:\n",
    "\n",
    "def kernel_function(X, Y):\n",
    "    return K_XY\n",
    "\n",
    "# kernels to compute: K_zz, K_zd, trace(K_dd)\n",
    "\n",
    "def lower_bound(D, m, S, Theta, T):\n",
    "    K_zz = ...\n",
    "    K_zz_inv = ...\n",
    "    \n",
    "    return - region_integral(m, S, K_zz_inv, Z, Theta, T) + datapoint_expectations(D, m, S, K_zz_inv, Theta) - kl_term(m,S,K_zz, K_zz_inv, Theta) \n",
    "\n",
    "def kl_term(m, S, K_zz, K_zz_inv, Theta):\n",
    "    return scalar_value_node\n",
    "\n",
    "def datapoint_expectations(D, m, S, K_zz_inv, Theta):\n",
    "    \n",
    "    k_zd = ...\n",
    "    k_dd = ...\n",
    "    \n",
    "    musqare_N = ...\n",
    "    sigsquare_N = ...\n",
    "    \n",
    "    C = 0.57721... #Euler-Masceroni constant\n",
    "    \n",
    "    lookup values = ... # problem: how to implement lookup table\n",
    "    \n",
    "    return scalar_value_node\n",
    "\n",
    "def region_integral(m, S, K_zz_inv, Z, Theta, T):\n",
    "    Psi = ... (MxM) \n",
    "    return scalar_value_node"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "tensorflowpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
