{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "na = np.newaxis\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/GPflow/GPflow/issues/439\n",
    "def tf_tril_indices(N, k=0):\n",
    "    M1 = tf.tile(tf.expand_dims(tf.range(N), axis=0), [N,1])\n",
    "    M2 = tf.tile(tf.expand_dims(tf.range(N), axis=1), [1,N])\n",
    "    mask = (M1-M2) >= -k\n",
    "    ix1 = tf.boolean_mask(M2, tf.transpose(mask))\n",
    "    ix2 = tf.boolean_mask(M1, tf.transpose(mask))\n",
    "    return ix1, ix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_lookup_table(file = 'g_lookup_table.npy'):\n",
    "    \n",
    "    return tf.convert_to_tensor(np.load(file), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def table_lookup_op_parallel(table, keys):\n",
    "    \n",
    "    table_keys = table[0]\n",
    "    table_vals = table[1]\n",
    "    \n",
    "    num_keys = tf.shape(keys)[0]\n",
    "    \n",
    "    # index from table value with closest table_key to given key\n",
    "    table_ind = tf.argmin( tf.abs(tf.expand_dims(table_keys, 0) - tf.expand_dims(keys, 1) ) , output_type=tf.int32, axis=1)\n",
    "    \n",
    "    top_keys = tf.gather(table_keys, table_ind)\n",
    "    \n",
    "    # difference from closest table_key to given key\n",
    "    shift     = keys - top_keys\n",
    "    \n",
    "    # -1 if table_ind == 0, 1 if table_ind > 0 (table ind always >= 0)\n",
    "    ti_zero_indicator = - tf.sign( tf.cast(tf.subtract(tf.ones([num_keys], dtype=tf.int32), tf.sign(table_ind)), dtype=tf.float32) - tf.constant(.5))\n",
    "    \n",
    "    # shift to next table entry (used for gradient computation)\n",
    "    # if table_key == key:\n",
    "    # if key != 0 : next smaller table_key is used\n",
    "    # if key == 0 : next greater table_key is used\n",
    "    nonzero_shift = (1 - tf.sign(tf.abs(shift))) * (-1. * ti_zero_indicator) + shift\n",
    "    \n",
    "    shift_step        = tf.cast(tf.sign(nonzero_shift), tf.int32) \n",
    "    table_ind_shifted = table_ind + shift_step\n",
    "    \n",
    "    table_val      = tf.gather(table_vals, table_ind)\n",
    "    next_table_val = tf.gather(table_vals, table_ind_shifted)\n",
    "    \n",
    "    table_key      = tf.gather(table_keys, table_ind)\n",
    "    next_table_key = tf.gather(table_keys, table_ind_shifted)\n",
    "    \n",
    "    dx = (next_table_key - table_key)\n",
    "    dy = (next_table_val - table_val)\n",
    "    \n",
    "    gradient               = dy / dx\n",
    "    interpolated_fun_value = table_val + shift * gradient\n",
    "    \n",
    "    return tf.stop_gradient(gradient) * keys + tf.stop_gradient(interpolated_fun_value - gradient * keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ard_kernel(X1, X2, gamma=1., alphas=None):\n",
    "    # X1:  (n1 x d)\n",
    "    # X2:  (n2 x d)\n",
    "    # out: (n1 x n2\n",
    "    with tf.name_scope('ard_kernel'):\n",
    "        if alphas is None:\n",
    "            alphas = tf.ones([tf.shape(X1)[1]])\n",
    "        return gamma * tf.reduce_prod(tf.exp(- (tf.expand_dims(X1, 1) - tf.expand_dims(X2, 0))**2 / (2 * tf.expand_dims(tf.expand_dims(alphas, 0), 0))), axis=2) \n",
    "\n",
    "\n",
    "def mu_tilde_square(X_data, Z, S, m, Kzz_inv):\n",
    "    k_zx = ard_kernel( Z,X_data, alphas=a_const)\n",
    "    k_xz = tf.transpose(k_zx)\n",
    "    K_xx = ard_kernel(X_data, X_data, alphas=a_const)\n",
    "    mu_sqr = tf.matmul(tf.matmul(tf.transpose(tf.expand_dims(m,1)),Kzz_inv)\n",
    "                                                     ,k_zx)**2\n",
    " \n",
    "    sig_sqr = K_xx - tf.matmul(tf.matmul(k_xz,K_zz_inv),k_zx) + tf.matmul(tf.matmul(tf.matmul(tf.matmul(k_xz,Kzz_inv),S),Kzz_inv),k_zx)\n",
    "\n",
    "    return mu_sqr,sig_sqr\n",
    "\n",
    "def kl_term(m, S, K_zz, K_zz_inv, u_ovln):\n",
    "    # mean_diff = (u_ovln * tf.ones([tf.shape(Z_ph)[0]]) - m)\n",
    "    mean_diff = tf.expand_dims(u_ovln * tf.ones([tf.shape(Z_ph)[0]]) - m, 1)\n",
    "    first  = tf.trace(tf.matmul(K_zz_inv, S))\n",
    "    second = tf.log(tf.matrix_determinant(K_zz) / tf.matrix_determinant(S))\n",
    "    third  = tf.to_float(tf.shape(m)[0])\n",
    "    # fourth = tf.reduce_sum(tf.multiply(tf.reduce_sum(tf.multiply(mean_diff, tf.transpose(K_zz_inv)), axis=1) , mean_diff))\n",
    "    \n",
    "    fourth = tf.squeeze(tf.matmul(tf.matmul(tf.transpose(mean_diff), K_zz_inv), mean_diff))\n",
    "    \n",
    "    return 0.5 * (first  + second - third + fourth)\n",
    "\n",
    "def psi_term(Z1, Z2,a,g,Tmin,Tmax):\n",
    "    z_ovln = (tf.expand_dims(Z1,1)+tf.expand_dims(Z2,0))/2\n",
    "    a_r = tf.expand_dims(tf.expand_dims(a,0),1)\n",
    "    \n",
    "    pi = tf.constant(math.pi)\n",
    "    \n",
    "    return g**2 * tf.reduce_prod(-(tf.sqrt(pi * a_r)/2\n",
    "                   ) * tf.exp(-tf.pow(tf.expand_dims(Z1,1) - tf.expand_dims(Z2,0),2) / (4 * a_r)\n",
    "                             ) * tf.erf((z_ovln-tf.expand_dims(tf.expand_dims(Tmax,0),1))/tf.sqrt(a_r)\n",
    "                                     ) - tf.erf((z_ovln-tf.expand_dims(tf.expand_dims(Tmin,0),1))/tf.sqrt(a_r)),2)\n",
    "\n",
    "def T_Integral(m, S, Kzz_inv,psi, g,Tmin, Tmax):\n",
    "    #e_qf = tf.matmul(m,tf.matmul(Kzz_inv,tf.matmul(psi,tf.matmul(Kzz_inv,m))))\n",
    "    e_qf = tf.matmul(tf.matmul(tf.matmul(tf.matmul(tf.transpose(tf.expand_dims(m,1)),Kzz_inv),psi),Kzz_inv),tf.expand_dims(m,1))\n",
    "    T = tf.reduce_prod(Tmax-Tmin)\n",
    "    var_qf = g * T - tf.trace(tf.matmul(Kzz_inv,psi)) + tf.trace(tf.matmul(tf.matmul(tf.matmul(Kzz_inv,S),Kzz_inv),psi))\n",
    "    return e_qf + var_qf\n",
    "\n",
    "def G(mu_sqr,sig_sqr_matrix):\n",
    "    \n",
    "    sig_sqr = tf.diag_part(sig_sqr_matrix)\n",
    "    lookup_x = - tf.squeeze(mu_sqr) / (2*sig_sqr)\n",
    "    \n",
    "    # return lookup_x\n",
    "    \n",
    "    # TODO: einkomment\n",
    "    lookup_table = load_lookup_table()\n",
    "    return table_lookup_op_parallel(lookup_table, lookup_x)\n",
    "    \n",
    "    \n",
    "def exp_at_datapoints(mu_sqr,sig_sqr,C):\n",
    "    return tf.reduce_sum(-G(mu_sqr,sig_sqr)+tf.log(mu_sqr/2)-C,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "Z_ph = tf.placeholder(tf.float32, [None, None], name='inducing_point_locations')\n",
    "u_ph = tf.placeholder(tf.float32, [],           name='inducing_point_mean')\n",
    "n_ph = tf.placeholder(tf.int32,   [],           name='number_samples')\n",
    "\n",
    "X_ph =tf.placeholder(tf.float32, [None, None])\n",
    "\n",
    "a_const = tf.ones([1]) # dimension = tf.shape(Z_ph)[1]\n",
    "g_const = tf.ones([1]) # later we have to define gamma as variable\n",
    "C = tf.constant(0.57721566)\n",
    "\n",
    "#Tlims\n",
    "Tmins = tf.reduce_min(Z_ph, axis=0)\n",
    "Tmaxs = tf.reduce_max(Z_ph, axis=0)\n",
    "\n",
    "num_inducing_points = 11 # tf.shape(Z_ph)[0] TODO: use shape of Z_ph instead? Right now, the number is defined twice (once here, one above in the definition of Z)\n",
    "\n",
    "# mean\n",
    "m_init = tf.ones([num_inducing_points])\n",
    "m = tf.Variable(m_init)\n",
    "\n",
    "# vectorized version of covariance matrix S (ensure valid covariance matrix)\n",
    "vech_size   = (num_inducing_points * (num_inducing_points+1)) / 2 \n",
    "vech_indices= tf.transpose(tf_tril_indices(num_inducing_points))\n",
    "L_vech_init = tf.ones([vech_size])\n",
    "L_vech = tf.Variable(L_vech_init)\n",
    "L_shape = tf.constant([num_inducing_points, num_inducing_points])\n",
    "L_st = tf.SparseTensor(tf.to_int64(vech_indices), L_vech, tf.to_int64(L_shape))\n",
    "L = tf.sparse_add(tf.zeros(L_shape), L_st)\n",
    "S = tf.matmul(L, tf.transpose(L))\n",
    "\n",
    "# kernel calls\n",
    "K_zz  = ard_kernel(Z_ph, Z_ph, alphas=a_const)\n",
    "K_zz_inv = tf.matrix_inverse(K_zz)\n",
    "\n",
    "with tf.name_scope('intergration-over-region-T'):\n",
    "    psi_matrix = psi_term(Z_ph,Z_ph,a_const,g_const,Tmins,Tmaxs)\n",
    "    integral_over_T = T_Integral(m,S,K_zz_inv,psi_matrix,g_const,Tmins,Tmaxs)\n",
    "    \n",
    "with tf.name_scope('expectation_at_datapoints'):\n",
    "    mu_t_sqr, sig_t_sqr = mu_tilde_square(X_ph,Z_ph,S,m,K_zz_inv)\n",
    "    exp_term = exp_at_datapoints(mu_t_sqr,sig_t_sqr,C)\n",
    "    \n",
    "    \n",
    "    sig_sqr = tf.diag_part(sig_t_sqr)\n",
    "    in_g_val = - tf.squeeze(mu_t_sqr) / (2*sig_sqr) \n",
    "\n",
    "with tf.name_scope('KL-divergence'):\n",
    "    kl_term_op = kl_term(m, S, K_zz, K_zz_inv, u_ph)\n",
    "    tf.summary.scalar('kl_div', kl_term_op)\n",
    "\n",
    "with tf.name_scope('calculate_bound'):\n",
    "    lower_bound = -integral_over_T + exp_term - kl_term_op\n",
    "    \n",
    "with tf.name_scope('optimization'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.001).minimize(-lower_bound)\n",
    "\n",
    "with tf.name_scope('prior_sampling'):\n",
    "    cov  = K_zz\n",
    "    mean = u_ph * tf.ones([num_inducing_points])\n",
    "    ind_point_dist = tf.contrib.distributions.MultivariateNormalFullCovariance(mean, cov)\n",
    "    samples = ind_point_dist.sample(n_ph)\n",
    "    \n",
    "m_grad = tf.gradients(kl_term_op, [m])[0]  \n",
    "L_vech_grad = tf.gradients(kl_term_op, [L_vech])[0]\n",
    "\n",
    "    \n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........\n",
      "[[-554.01104736]]\n",
      "[-0.30560243 -0.40847099 -0.35915816 -0.31738538 -0.33168599 -0.35080644\n",
      " -0.3362048  -0.33171618 -0.34115359 -0.44091654]\n",
      "..........\n",
      "[[-222.37870789]]\n",
      "[ -3.43889785 -10.14654827  -5.87465572  -3.67795753  -4.09985781\n",
      "  -5.12037563  -4.52327013  -4.34702682  -4.56320429 -17.16475105]\n",
      "..........\n",
      "[[-158.84500122]]\n",
      "[ -6.92291307 -20.36220932 -11.64884472  -7.48857784  -8.46676731\n",
      " -10.39805508  -9.11035538  -8.74897289  -9.35828781 -33.08942795]\n",
      "..........\n",
      "[[-122.99356079]]\n",
      "[-11.52023125 -33.48563004 -19.0013485  -12.62526417 -14.44328594\n",
      " -17.40238571 -15.13853931 -14.53036976 -15.83311844 -52.7058754 ]\n",
      "..........\n",
      "[[-79.61817169]]\n",
      "[-17.87254143 -51.38672256 -28.93497658 -19.83187675 -22.9222908\n",
      " -27.13115883 -23.45102501 -22.49812698 -24.93323708 -79.00804901]\n",
      "..........\n",
      "[[-10.64123535]]\n",
      "[ -27.15439415  -77.32461548  -43.2389946   -30.4603157   -35.49303818\n",
      "  -41.38575745  -35.57977295  -34.12007523  -38.35613251 -116.72941589]\n",
      "..........\n",
      "[[ 109.70430756]]\n",
      "[ -41.45131302 -117.00242615  -65.07589722  -46.89787674  -54.91973114\n",
      "  -63.33788681  -54.23688126  -51.99645615  -59.07223511 -174.10528564]\n",
      "..........\n",
      "[[ 328.43292236]]\n",
      "[ -64.41863251 -180.2996521   -99.99520111  -73.28881836  -85.89766693\n",
      "  -98.48209381  -84.16151428  -80.67507935  -92.1738205  -265.55575562]\n",
      "..........\n",
      "[[ 734.92175293]]\n",
      "[-102.50119781 -284.37335205 -157.83364868 -116.82479095 -136.31840515\n",
      " -156.33680725 -133.67510986 -128.1522522  -146.33958435 -416.5980835 ]\n",
      "..........\n",
      "[[ 1500.67456055]]\n",
      "[-167.11021423 -458.90838623 -256.18304443 -189.9241333  -219.17791748\n",
      " -253.30256653 -217.41934204 -208.52819824 -236.15855408 -672.72460938]\n",
      "..........\n",
      "[[ 2955.91162109]]\n",
      "[ -278.3861084   -754.40325928  -426.62173462  -313.65841675  -354.9989624\n",
      "  -417.11340332  -360.98101807  -346.52838135  -385.38842773 -1115.22290039]\n",
      "..........\n",
      "[[ 5737.66357422]]\n",
      "[ -471.34613037 -1253.42529297  -725.60516357  -522.41955566  -573.70355225\n",
      "  -692.76171875  -608.12573242  -584.68408203  -630.3550415  -1888.32580566]\n",
      "..........\n",
      "[[ 11076.47753906]]\n",
      "[ -804.76263428 -2080.43383789 -1252.43981934  -868.13549805  -912.62384033\n",
      " -1147.3972168  -1030.27709961  -993.07147217 -1020.16296387 -3242.4855957 ]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[9] = -1 is not in [0, 10000)\n\t [[Node: expectation_at_datapoints/Gather_4 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](expectation_at_datapoints/strided_slice, expectation_at_datapoints/add_2)]]\n\nCaused by op 'expectation_at_datapoints/Gather_4', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-2e2349e335a1>\", line 43, in <module>\n    exp_term = exp_at_datapoints(mu_t_sqr,sig_t_sqr,C)\n  File \"<ipython-input-5-2940b43b21cd>\", line 65, in exp_at_datapoints\n    return tf.reduce_sum(-G(mu_sqr,sig_sqr)+tf.log(mu_sqr/2)-C,axis=1)\n  File \"<ipython-input-5-2940b43b21cd>\", line 61, in G\n    return table_lookup_op_parallel(lookup_table, lookup_x)\n  File \"<ipython-input-4-73e313693e7d>\", line 32, in table_lookup_op_parallel\n    next_table_key = tf.gather(table_keys, table_ind_shifted)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[9] = -1 is not in [0, 10000)\n\t [[Node: expectation_at_datapoints/Gather_4 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](expectation_at_datapoints/strided_slice, expectation_at_datapoints/add_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[9] = -1 is not in [0, 10000)\n\t [[Node: expectation_at_datapoints/Gather_4 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](expectation_at_datapoints/strided_slice, expectation_at_datapoints/add_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-109cb376c679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         _, summary, g_in, kl, exp_val,mu,sig,integral,bound, m_val, S_val = sess.run([train_step, merged,  in_g_val, kl_term_op,exp_term,mu_t_sqr, sig_t_sqr , integral_over_T ,lower_bound, m, S], \n\u001b[0;32m---> 21\u001b[0;31m                                                      feed_dict={Z_ph:Z, u_ph:0.,X_ph:X})\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[9] = -1 is not in [0, 10000)\n\t [[Node: expectation_at_datapoints/Gather_4 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](expectation_at_datapoints/strided_slice, expectation_at_datapoints/add_2)]]\n\nCaused by op 'expectation_at_datapoints/Gather_4', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-2e2349e335a1>\", line 43, in <module>\n    exp_term = exp_at_datapoints(mu_t_sqr,sig_t_sqr,C)\n  File \"<ipython-input-5-2940b43b21cd>\", line 65, in exp_at_datapoints\n    return tf.reduce_sum(-G(mu_sqr,sig_sqr)+tf.log(mu_sqr/2)-C,axis=1)\n  File \"<ipython-input-5-2940b43b21cd>\", line 61, in G\n    return table_lookup_op_parallel(lookup_table, lookup_x)\n  File \"<ipython-input-4-73e313693e7d>\", line 32, in table_lookup_op_parallel\n    next_table_key = tf.gather(table_keys, table_ind_shifted)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\", line 2486, in gather\n    params, indices, validate_indices=validate_indices, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 1834, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): indices[9] = -1 is not in [0, 10000)\n\t [[Node: expectation_at_datapoints/Gather_4 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](expectation_at_datapoints/strided_slice, expectation_at_datapoints/add_2)]]\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 1500\n",
    "\n",
    "# inducing point location\n",
    "Zx = np.linspace(0, 20, 11)[:,na]\n",
    "Zy = np.linspace(0, 10, 11)[:,na]\n",
    "\n",
    "Z = np.concatenate((Zx,Zy),axis=1)\n",
    "\n",
    "X = np.random.rand(10,2)\n",
    "\n",
    "wr_means = []\n",
    "wr_covar = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        _, summary, g_in, kl, exp_val,mu,sig,integral,bound, m_val, S_val = sess.run([train_step, merged,  in_g_val, kl_term_op,exp_term,mu_t_sqr, sig_t_sqr , integral_over_T ,lower_bound, m, S], \n",
    "                                                     feed_dict={Z_ph:Z, u_ph:0.,X_ph:X})\n",
    "        writer.add_summary(summary, i)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print('..........')\n",
    "            print(bound)\n",
    "            #print(exp_val)\n",
    "            #print(sig)\n",
    "            #print(mu.shape)\n",
    "            print(g_in)\n",
    "            #print(sig)\n",
    "            #print(np.max(np.absolute(S_val)))\n",
    "            #print(np.all(np.linalg.eigvals(S_val) > 0))\n",
    "            \n",
    "            plt.scatter(i, bound)\n",
    "            \n",
    "        if np.isclose(kl, 0):\n",
    "            print('KL is zero after {} iterations... break'.format(i))\n",
    "            break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy ard_kernel calculation\n",
    "def ard_kernel_np(X1, X2, gamma = 1., alphas = None):\n",
    "    \n",
    "    if alphas == None:\n",
    "        alphas = np.ones(X1.shape[1])\n",
    "    \n",
    "    return gamma * np.prod(np.exp( - (X1[:,None,:] - X2[None,:,:])**2 / (2 * alphas[None,None,:])), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "r_mean = np.zeros(num_inducing_points)\n",
    "r_cov = ard_kernel_np(Z, Z)\n",
    "\n",
    "print(np.allclose(r_mean, m_val))\n",
    "print(np.allclose(r_cov, S_val))\n",
    "\n",
    "print(np.sum(r_cov - S_val)**2)\n",
    "\n",
    "# values not allclose but almost the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "num_samples = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    sample_res, mean_res, cov_res = sess.run([samples, mean, cov], feed_dict={Z_ph:Z, u_ph:0., n_ph:num_samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    plt.plot(Z, sample_res[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inputs:\n",
    "Domain $X = \\mathbb{R}^R$ ($R$-Dimensional)\n",
    "$T \\subset X$\n",
    "\n",
    "\n",
    "### Fixed:\n",
    "\n",
    "#### General:\n",
    "- R\n",
    "- Tlims: (Rx2)\n",
    "- Data D: (NxR) (all points in T)\n",
    "\n",
    "#### Inducing points:\n",
    "    -> fix nbr M \n",
    "    -> Z: (MxR) location\n",
    "    -> u: (M) (each sample of function values at the inducing points is M dimensional) \n",
    "\n",
    "#### Hyperparameters ($\\Theta$)\n",
    "    -> fixed at first, might become be optimized later as well\n",
    "$\\Theta = (\\gamma, \\alpha_1,...,  \\alpha_R, \\overline{u})$\n",
    "\n",
    "\n",
    "### Parameters:\n",
    "variational dist at inducing points u: q(u) = N (u;m,S)\n",
    "\n",
    "m: (M)\n",
    "\n",
    "S: (MxM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pseudo stuff, no working code!!!\n",
    "\n",
    "# constants:\n",
    "# - R, T, M\n",
    "# - D (NxR)\n",
    "# - Z (MxR)\n",
    "# - Theta values (gamma, alphas, ustrich)\n",
    "\n",
    "# placeholders:\n",
    "# - m (M)\n",
    "# - S (MxM)\n",
    "\n",
    "\n",
    "# kernel stuff:\n",
    "\n",
    "def kernel_function(X, Y):\n",
    "    return K_XY\n",
    "\n",
    "# kernels to compute: K_zz, K_zd, trace(K_dd)\n",
    "\n",
    "def lower_bound(D, m, S, Theta, T):\n",
    "    K_zz = ...\n",
    "    K_zz_inv = ...\n",
    "    \n",
    "    return - region_integral(m, S, K_zz_inv, Z, Theta, T) + datapoint_expectations(D, m, S, K_zz_inv, Theta) - kl_term(m,S,K_zz, K_zz_inv, Theta) \n",
    "\n",
    "def kl_term(m, S, K_zz, K_zz_inv, Theta):\n",
    "    return scalar_value_node\n",
    "\n",
    "def datapoint_expectations(D, m, S, K_zz_inv, Theta):\n",
    "    \n",
    "    k_zd = ...\n",
    "    k_dd = ...\n",
    "    \n",
    "    musqare_N = ...\n",
    "    sigsquare_N = ...\n",
    "    \n",
    "    C = 0.57721... #Euler-Masceroni constant\n",
    "    \n",
    "    lookup values = ... # problem: how to implement lookup table\n",
    "    \n",
    "    return scalar_value_node\n",
    "\n",
    "def region_integral(m, S, K_zz_inv, Z, Theta, T):\n",
    "    Psi = ... (MxM) \n",
    "    return scalar_value_node"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
