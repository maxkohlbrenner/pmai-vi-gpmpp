{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "na = np.newaxis\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inputs:\n",
    "Domain $X = \\mathbb{R}^R$ ($R$-Dimensional)\n",
    "$T \\subset X$\n",
    "\n",
    "\n",
    "### Fixed:\n",
    "\n",
    "#### General:\n",
    "- R\n",
    "- Tlims: (Rx2)\n",
    "- Data D: (NxR) (all points in T)\n",
    "\n",
    "#### Inducing points:\n",
    "    -> fix nbr M \n",
    "    -> Z: (MxR) location\n",
    "    -> u: (M) (each sample of function values at the inducing points is M dimensional) \n",
    "\n",
    "#### Hyperparameters ($\\Theta$)\n",
    "    -> fixed at first, might become be optimized later as well\n",
    "$\\Theta = (\\gamma, \\alpha_1,...,  \\alpha_R, \\overline{u})$\n",
    "\n",
    "\n",
    "### Parameters:\n",
    "variational dist at inducing points u: q(u) = N (u;m,S)\n",
    "\n",
    "m: (M)\n",
    "\n",
    "S: (MxM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pseudo stuff, no working code!!!\n",
    "\n",
    "# constants:\n",
    "# - R, T, M\n",
    "# - D (NxR)\n",
    "# - Z (MxR)\n",
    "# - Theta values (gamma, alphas, ustrich)\n",
    "\n",
    "# placeholders:\n",
    "# - m (M)\n",
    "# - S (MxM)\n",
    "\n",
    "\n",
    "# kernel stuff:\n",
    "\n",
    "def kernel_function(X, Y):\n",
    "    return K_XY\n",
    "\n",
    "# kernels to compute: K_zz, K_zd, trace(K_dd)\n",
    "\n",
    "def lower_bound(D, m, S, Theta, T):\n",
    "    K_zz = ...\n",
    "    K_zz_inv = ...\n",
    "    \n",
    "    return - region_integral(m, S, K_zz_inv, Z, Theta, T) + datapoint_expectations(D, m, S, K_zz_inv, Theta) - kl_term(m,S,K_zz, K_zz_inv, Theta) \n",
    "\n",
    "def kl_term(m, S, K_zz, K_zz_inv, Theta):\n",
    "    return scalar_value_node\n",
    "\n",
    "def datapoint_expectations(D, m, S, K_zz_inv, Theta):\n",
    "    \n",
    "    k_zd = ...\n",
    "    k_dd = ...\n",
    "    \n",
    "    musqare_N = ...\n",
    "    sigsquare_N = ...\n",
    "    \n",
    "    C = 0.57721... #Euler-Masceroni constant\n",
    "    \n",
    "    lookup values = ... # problem: how to implement lookup table\n",
    "    \n",
    "    return scalar_value_node\n",
    "\n",
    "def region_integral(m, S, K_zz_inv, Z, Theta, T):\n",
    "    Psi = ... (MxM) \n",
    "    return scalar_value_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inducing point locations\n",
    "Z = np.linspace(0, 10, 11)[:,na]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/GPflow/GPflow/issues/439\n",
    "def tf_tril_indices(N, k=0):\n",
    "    M1 = tf.tile(tf.expand_dims(tf.range(N), axis=0), [N,1])\n",
    "    M2 = tf.tile(tf.expand_dims(tf.range(N), axis=1), [1,N])\n",
    "    mask = (M1-M2) >= -k\n",
    "    ix1 = tf.boolean_mask(M2, tf.transpose(mask))\n",
    "    ix2 = tf.boolean_mask(M1, tf.transpose(mask))\n",
    "    return ix1, ix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ard_kernel(X1, X2, gamma=1., alphas=None):\n",
    "    # X1:  (n1 x d)\n",
    "    # X2:  (n2 x d)\n",
    "    # out: (n1 x n2\n",
    "    \n",
    "    with tf.name_scope('ard_kernel'):\n",
    "        if alphas is None:\n",
    "            alphas = tf.ones([tf.shape(X1)[1]])\n",
    "        return gamma * tf.reduce_prod(tf.exp(- (tf.expand_dims(X1, 1) - tf.expand_dims(X2, 0))**2 / (2 * tf.expand_dims(tf.expand_dims(alphas, 0), 0))), axis=2) \n",
    "\n",
    "def kl_term(m, S, K_zz, K_zz_inv, u_ovln):\n",
    "    mean_diff = (u_ovln * tf.ones([tf.shape(Z_ph)[0]]) - m)\n",
    "    first  = tf.trace(tf.matmul(K_zz_inv, S))\n",
    "    second = tf.log(tf.norm(K_zz) / tf.norm(S))\n",
    "    third  = tf.to_float(tf.shape(m)[0])\n",
    "    fourth = tf.reduce_sum(tf.multiply(tf.reduce_sum(tf.multiply(mean_diff, tf.transpose(K_zz_inv)), axis=1) , mean_diff))\n",
    "    return 0.5 * (first  - second - third + fourth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "Z_ph = tf.placeholder(tf.float32, [None, None], name='inducing_point_locations')\n",
    "u_ph = tf.placeholder(tf.float32, [],           name='inducin_point_mean')\n",
    "n_ph = tf.placeholder(tf.int32,   [],           name='number_samples')\n",
    "\n",
    "\n",
    "num_inducing_points = 11# tf.shape(Z_ph)[0] TODO: was da tun?\n",
    "\n",
    "# mean\n",
    "m_init = tf.zeros([num_inducing_points])\n",
    "m = tf.Variable(m_init)\n",
    "\n",
    "# vectorized version of covariance matrix S (ensure valid covariance matrix)\n",
    "vech_size   = (num_inducing_points * (num_inducing_points+1)) / 2 \n",
    "vech_indices= tf.transpose(tf_tril_indices(num_inducing_points))\n",
    "L_vech_init = tf.ones([vech_size])\n",
    "\n",
    "L_vech = tf.Variable(L_vech_init)\n",
    "\n",
    "L = tf.sparse_to_dense(vech_indices, [num_inducing_points, num_inducing_points], L_vech)\n",
    "S = tf.matmul(L, tf.transpose(L))\n",
    "\n",
    "K_zz  = ard_kernel(Z_ph, Z_ph)\n",
    "K_zz_inv = tf.matrix_inverse(K_zz)\n",
    "\n",
    "with tf.name_scope('approximation'):\n",
    "    kl_term_op = kl_term(m, S, K_zz, K_zz_inv, u_ph)\n",
    "    tf.summary.scalar('kl_div', kl_term_op)\n",
    "    \n",
    "with tf.name_scope('optimization'):\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(kl_term_op)\n",
    "\n",
    "with tf.name_scope('prior_sampling'):\n",
    "    cov  = K_zz\n",
    "    mean = u_ph * tf.ones([num_inducing_points])\n",
    "    ind_point_dist = tf.contrib.distributions.MultivariateNormalFullCovariance(mean, cov)\n",
    "    samples = ind_point_dist.sample(n_ph)\n",
    "    \n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "16.9261\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.]\n",
      " [  1.   2.   3.   3.   3.   3.   3.   3.   3.   3.   3.]\n",
      " [  1.   2.   3.   4.   4.   4.   4.   4.   4.   4.   4.]\n",
      " [  1.   2.   3.   4.   5.   5.   5.   5.   5.   5.   5.]\n",
      " [  1.   2.   3.   4.   5.   6.   6.   6.   6.   6.   6.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   7.   7.   7.   7.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   8.   8.   8.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.   9.   9.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  10.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.]]\n",
      "------------------------\n",
      "16.9261\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.]\n",
      " [  1.   2.   3.   3.   3.   3.   3.   3.   3.   3.   3.]\n",
      " [  1.   2.   3.   4.   4.   4.   4.   4.   4.   4.   4.]\n",
      " [  1.   2.   3.   4.   5.   5.   5.   5.   5.   5.   5.]\n",
      " [  1.   2.   3.   4.   5.   6.   6.   6.   6.   6.   6.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   7.   7.   7.   7.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   8.   8.   8.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.   9.   9.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  10.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.]]\n",
      "------------------------\n",
      "16.9261\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.]\n",
      " [  1.   2.   3.   3.   3.   3.   3.   3.   3.   3.   3.]\n",
      " [  1.   2.   3.   4.   4.   4.   4.   4.   4.   4.   4.]\n",
      " [  1.   2.   3.   4.   5.   5.   5.   5.   5.   5.   5.]\n",
      " [  1.   2.   3.   4.   5.   6.   6.   6.   6.   6.   6.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   7.   7.   7.   7.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   8.   8.   8.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.   9.   9.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  10.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.]]\n",
      "------------------------\n",
      "16.9261\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.]\n",
      " [  1.   2.   3.   3.   3.   3.   3.   3.   3.   3.   3.]\n",
      " [  1.   2.   3.   4.   4.   4.   4.   4.   4.   4.   4.]\n",
      " [  1.   2.   3.   4.   5.   5.   5.   5.   5.   5.   5.]\n",
      " [  1.   2.   3.   4.   5.   6.   6.   6.   6.   6.   6.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   7.   7.   7.   7.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   8.   8.   8.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.   9.   9.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  10.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.]]\n",
      "------------------------\n",
      "16.9261\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[[  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.]\n",
      " [  1.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.]\n",
      " [  1.   2.   3.   3.   3.   3.   3.   3.   3.   3.   3.]\n",
      " [  1.   2.   3.   4.   4.   4.   4.   4.   4.   4.   4.]\n",
      " [  1.   2.   3.   4.   5.   5.   5.   5.   5.   5.   5.]\n",
      " [  1.   2.   3.   4.   5.   6.   6.   6.   6.   6.   6.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   7.   7.   7.   7.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   8.   8.   8.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.   9.   9.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  10.]\n",
      " [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.]]\n"
     ]
    }
   ],
   "source": [
    "max_iterations = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        _, summary, kl, m_val, s_val = sess.run([train_step, merged, kl_term_op, m, S], feed_dict={Z_ph:Z, u_ph:0.})\n",
    "        writer.add_summary(summary, i)\n",
    "        print('------------------------')\n",
    "        print(kl)\n",
    "        print(m_val)\n",
    "        print(s_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "num_samples = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "    sample_res, mean_res, cov_res = sess.run([samples, mean, cov], feed_dict={Z_ph:Z, u_ph:0., n_ph:num_samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    plt.plot(Z, sample_res[i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
